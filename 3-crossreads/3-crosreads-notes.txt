

DATA: WWI soldiers diaries
http://ww1.sl.nsw.gov.au/content/james-macdonald
http://www.acmssearch.sl.nsw.gov.au/search/itemDetailPaged.cgi?itemID=872426
http://acms.sl.nsw.gov.au/_transcript/2014/D25496/a6667.html

A transcription:
http://acms.sl.nsw.gov.au/_transcript/2014/D25496/a6667.html


EAMPLES OF NETWORK APPS:

- List: D3js: https://github.com/mbostock/d3/wiki/Gallery
- balls and edges + click and select subnet: http://fatiherikli.github.io/programming-language-network/#language:Python
- Hive plot: http://bost.ocks.org/mike/hive/
- d3 process map: http://nylen.tv/d3-process-map/graph.php
- GraphGL: https://github.com/uskudnik/GraphGL



The diaries as a matrix of pages , where each column is a Diary (129)
1.DOME) prepare dummy data
2) Prepare html using AngularJS
3) d3js -> write connections along pages visited in a session(*)
	(*) Check where to save the user data: HTML5 store, cookie, session?

Parallely to-do: data analysis
1.DONE) simple explorer of the text of pages (python console program)
2) 

#######################################################################
#######################################################################
#######################################################################

3-CROSSREADS:


INTERFACE:	

- Final version can be totally-static. It means that code is not building interface upon json data, but using jsn data to flter, browse and so on.

- Similar cases:
	* 5 Visualizing Lexical Novelty in Literature by Matthew Hurst (2011)
	* 6 On the Origin of Species: The Preservation of Favoured Traces by Ben Fry (2009)
	* 7 Texty, a visualization tool to aid selection of texts from search outputs by Jaume Nualart (2008)
			Texty could be used instead of on-item-per-page
	*! 8 Bible Cross-References by Chris Harrison (2008)

DATA:
	- We are going to use MALLET for topic model analysis
		* Referencies:
			> Topic Modeling Martha Ballardâ€™s Diaryby Cameron Blevins (2010) 
				http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/
			> 
	- Analysis:
		* Topic models by page. Page is the text segment unit
		* Timaline of all cross-diaries topics: evolution of topics from 1914 to 1919
		* 
		
  ToDo:
    - Build real data:
      * Define all possible/desirable attributes for diaries and pages metadata
      * Define the method to get each attribute
      * Build real data for data.js and each_page.js
    -  

