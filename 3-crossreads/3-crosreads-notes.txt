

DATA: WWI soldiers diaries
Transcripts -> http://transcripts.sl.nsw.gov.au/

http://ww1.sl.nsw.gov.au/content/james-macdonald
http://www.acmssearch.sl.nsw.gov.au/search/itemDetailPaged.cgi?itemID=872426
http://acms.sl.nsw.gov.au/_transcript/2014/D25496/a6667.html

A transcription:
http://acms.sl.nsw.gov.au/_transcript/2014/D25496/a6667.html



PAGES IMAGES:

Diary list of pages (thumbnails): http://transcripts.sl.nsw.gov.au/page/100427/view
Page 36th thumbnail: http://transcripts.sl.nsw.gov.au/sites/all/files/a7172016h.jpg
Page 16th view: http://transcripts.sl.nsw.gov.au/page/100427/view
Page 16th big image: http://transcripts.sl.nsw.gov.au/sites/all/files/a7172016h.jpg

http://transcripts.sl.nsw.gov.au/page/100328/view

AUTHOR PAGES:
Search:
http://www.acmssearch.sl.nsw.gov.au/s/search.html?collection=slnsw-artist&query=Archie+Barwick&type=1&meta_S=&submit-artist=Search


DIARIES TO CHECK:
Empty pages. With on a "*.html" file
diary-104.txt  diary-110.txt  diary-36.txt  diary-52.txt  diary-54.txt  diary-75.txt  diary-83.txt  diary-88.txt  diary-98.txt
diary-109.txt  diary-113.txt  diary-45.txt  diary-53.txt  diary-66.txt  diary-81.txt  diary-87.txt  diary-89.txt

* 127 -> Is empty and there is no  link to transcripts:
         http://transcripts.sl.nsw.gov.au/node/115137

################################################
################################################
################################################



EAMPLES OF NETWORK APPS:

- List: D3js: https://github.com/mbostock/d3/wiki/Gallery
- balls and edges + click and select subnet: http://fatiherikli.github.io/programming-language-network/#language:Python
- Hive plot: http://bost.ocks.org/mike/hive/
- d3 process map: http://nylen.tv/d3-process-map/graph.php
- GraphGL: https://github.com/uskudnik/GraphGL



The diaries as a matrix of pages , where each column is a Diary (129)
1.DOME) prepare dummy data
2) Prepare html using AngularJS
3) d3js -> write connections along pages visited in a session(*)
	(*) Check where to save the user data: HTML5 store, cookie, session?

Parallely to-do: data analysis
1.DONE) simple explorer of the text of pages (python console program)
2) 




ABOUT ANZAC 100 ANIVERSARI
- 18 Powerful Photos Of The Forgotten Indigenous Soldiers Of World War I
	http://www.buzzfeed.com/jennaguillaume/powerful-photos-of-forgotten-indigenous-soldiers-of-wwi#.vbnbnD9AY
- 8 Things You May Not Know About the Gallipoli Campaign
	http://www.history.com/news/8-things-you-may-not-know-about-the-gallipoli-campaign?cmpid=Social_FBPAGE_HISTORY_20150425_172975093&linkId=13760087

#######################################################################
#######################################################################
#######################################################################

3-CROSSREADS:


INTERFACE:	

- Final version can be totally-static. It means that code is not building interface upon json data, but using jsn data to flter, browse and so on. Maybe backgroung svg image + transparent svg on top  for all interactions

- Similar cases:
	* 5 Visualizing Lexical Novelty in Literature by Matthew Hurst (2011)
	* 6 On the Origin of Species: The Preservation of Favoured Traces by Ben Fry (2009)
	* 7 Texty, a visualization tool to aid selection of texts from search outputs by Jaume Nualart (2008)
			Texty could be used instead of on-item-per-page
	*! 8 Bible Cross-References by Chris Harrison (2008)

DATA:
	- We are going to use MALLET for topic model analysis
		* Referencies:
			> Topic Modeling Martha Ballardâ€™s Diaryby Cameron Blevins (2010) 
				http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/
			> 
	- Analysis:
		* Topic models by page. Page is the text segment unit
		* Timaline of all cross-diaries topics: evolution of topics from 1914 to 1919
		* 
		
DATA ToDo:
    - Build real data:
DONE      * Define all possible/desirable attributes for diaries metadata
DONE      * Define the method to get each attribute
DONE      * Build a basic data.js with real data
            > To be implemented in data.js:
              >> Define all possible/desirable attributes for pages
              >> TRY diary-page date and location extraction/indexetion
              >> topics with Mallet
              >> locations with entity-recognition per PAGE
              >> GET Diary metadata from State Library NSW
              >> GET authors info: as json?
              
          * Crossreads-data-structure: join pages from each diary (as crossreads-data 1 and 2) page.js

